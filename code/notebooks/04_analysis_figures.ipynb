{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Analysis & Figures for Report\n",
    "\n",
    "This notebook generates publication-ready figures for the AGRE-KD feature distillation report.\n",
    "\n",
    "**Figures to generate:**\n",
    "1. Œ≥ (gamma) sweep bar chart - Main experimental result\n",
    "2. Waterbirds dataset 2x2 visualization - Help readers understand spurious correlations\n",
    "3. AGRE-KD vs AVER comparison line plot (optional)\n",
    "4. Summary results table - Color-coded table with WGA and Avg Acc ¬± std\n",
    "5. Horizontal bar comparison - Side-by-side WGA and Avg Acc visualization\n",
    "\n",
    "**Output:** Figures saved to `blog/images/` for inclusion in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q wilds tqdm scikit-learn\n",
    "\n",
    "# Verify GPU (optional for figure generation)\n",
    "import torch\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURE YOUR PATHS HERE\n",
    "# ============================================================\n",
    "GITHUB_REPO = 'dat-tran05/robust-ensemble-kd'\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/MIT/MIT Junior Year (2025-2026)/Fall Semester/6.7960/6.7960 Final Project/robust-ensemble-kd'\n",
    "\n",
    "# Derived paths\n",
    "CODE_DIR = '/content/repo'\n",
    "DATA_DIR = f'{DRIVE_ROOT}/data/waterbirds_v1.0'\n",
    "LOG_DIR = f'{DRIVE_ROOT}/logs'\n",
    "OUTPUT_DIR = f'{CODE_DIR}/blog/images'  # Save figures here\n",
    "\n",
    "# Create output directory if needed\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Drive root: {DRIVE_ROOT}\")\n",
    "print(f\"Data: {DATA_DIR}\")\n",
    "print(f\"Logs: {LOG_DIR}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone or update repository\n",
    "if os.path.exists(CODE_DIR):\n",
    "    print(\"Repository exists, pulling latest...\")\n",
    "    %cd {CODE_DIR}\n",
    "    !git pull\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone https://github.com/{GITHUB_REPO}.git {CODE_DIR}\n",
    "    %cd {CODE_DIR}\n",
    "\n",
    "# Navigate to code directory\n",
    "%cd {CODE_DIR}/code\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, f'{CODE_DIR}/code')\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ Load Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original results (no seed set - treat as additional data point 'og')\n",
    "# Original results (no seed set - treat as additional data point 'og')\n",
    "ORIGINAL_RESULTS = {\n",
    "    'aver_baseline': {\n",
    "        'wga': 83.33,\n",
    "        'avg_acc': 92.79,\n",
    "        'alpha': 1.0,\n",
    "        'gamma': 0.0,\n",
    "        'use_agre': False\n",
    "    },\n",
    "    'baseline_agrekd': {\n",
    "        'wga': 85.05,\n",
    "        'avg_acc': 91.42,\n",
    "        'alpha': 1.0,\n",
    "        'gamma': 0.0,\n",
    "        'use_agre': True\n",
    "    },\n",
    "    'exp1_alpha07': {\n",
    "        'wga': 82.55,\n",
    "        'avg_acc': 92.34,\n",
    "        'alpha': 0.7,\n",
    "        'gamma': 0.0,\n",
    "        'use_agre': True\n",
    "    },\n",
    "    'exp1_alpha09': {\n",
    "        'wga': 83.80,\n",
    "        'avg_acc': 93.01,\n",
    "        'alpha': 0.9,\n",
    "        'gamma': 0.0,\n",
    "        'use_agre': True\n",
    "    },\n",
    "    'exp2_gamma01': {\n",
    "        'wga': 85.10,\n",
    "        'avg_acc': 90.94,\n",
    "        'alpha': 1.0,\n",
    "        'gamma': 0.1,\n",
    "        'use_agre': True\n",
    "    },\n",
    "    'exp2_gamma025': {\n",
    "        'wga': 86.29,\n",
    "        'avg_acc': 92.96,\n",
    "        'alpha': 1.0,\n",
    "        'gamma': 0.25,\n",
    "        'use_agre': True\n",
    "    },\n",
    "    'exp3_combined': {\n",
    "        'wga': 83.18,\n",
    "        'avg_acc': 92.72,\n",
    "        'alpha': 0.7,\n",
    "        'gamma': 0.1,\n",
    "        'use_agre': True\n",
    "    },\n",
    "}\n",
    "\n",
    "# Load seeded results\n",
    "log_path = os.path.join(LOG_DIR, 'seed_experiment_results.json')\n",
    "if os.path.exists(log_path):\n",
    "    with open(log_path, 'r') as f:\n",
    "        seed_results = json.load(f)\n",
    "    print(f\"‚úÖ Loaded {len(seed_results)} seeded experiment results\")\n",
    "else:\n",
    "    seed_results = {}\n",
    "    print(f\"‚ö†Ô∏è No seeded results found at {log_path}\")\n",
    "\n",
    "# Build combined dataframe\n",
    "rows = []\n",
    "\n",
    "# Add original results\n",
    "for base_exp, data in ORIGINAL_RESULTS.items():\n",
    "    rows.append({\n",
    "        'Experiment': base_exp,\n",
    "        'Seed': 'og',\n",
    "        'Œ±': data['alpha'],\n",
    "        'Œ≥': data['gamma'],\n",
    "        'Method': 'AGRE-KD' if data['use_agre'] else 'AVER',\n",
    "        'WGA (%)': data['wga'],\n",
    "        'Avg Acc (%)': data['avg_acc'],\n",
    "    })\n",
    "\n",
    "# Add seeded results\n",
    "for exp_name, data in seed_results.items():\n",
    "    base_exp = data.get('base_exp', exp_name.rsplit('_seed', 1)[0])\n",
    "    is_aver = 'aver' in base_exp.lower()\n",
    "    is_multilayer = base_exp.startswith('ml_')\n",
    "    is_disagree = 'disagree' in base_exp.lower()\n",
    "    alpha = data.get('alpha', 1.0)\n",
    "    \n",
    "    if is_multilayer:\n",
    "        method = 'Multi-Layer'\n",
    "    elif is_disagree:\n",
    "        method = 'Disagree-Weight'\n",
    "    elif is_aver:\n",
    "        method = 'AVER'\n",
    "    else:\n",
    "        method = 'AGRE-KD'\n",
    "    \n",
    "    rows.append({\n",
    "        'Experiment': base_exp,\n",
    "        'Seed': str(data.get('seed', 'N/A')),\n",
    "        'Œ±': alpha,\n",
    "        'Œ≥': data['gamma'],\n",
    "        'Method': method,\n",
    "        'WGA (%)': round(data['wga'] * 100, 2),\n",
    "        'Avg Acc (%)': round(data.get('avg_acc', 0) * 100, 2),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['Seed'] = df['Seed'].astype(str)\n",
    "\n",
    "print(f\"\\n‚úÖ Combined {len(df)} total experiment runs\")\n",
    "print(f\"   Unique experiments: {df['Experiment'].nunique()}\")\n",
    "print(f\"   Seeds: {sorted(df['Seed'].unique())}\")\n",
    "\n",
    "# Load seeded results\n",
    "log_path = os.path.join(LOG_DIR, 'seed_experiment_results.json')\n",
    "if os.path.exists(log_path):\n",
    "    with open(log_path, 'r') as f:\n",
    "        seed_results = json.load(f)\n",
    "    print(f\"‚úÖ Loaded {len(seed_results)} seeded experiment results\")\n",
    "else:\n",
    "    seed_results = {}\n",
    "    print(f\"‚ö†Ô∏è No seeded results found at {log_path}\")\n",
    "\n",
    "# Build combined dataframe\n",
    "rows = []\n",
    "\n",
    "# Add original results\n",
    "for base_exp, data in ORIGINAL_RESULTS.items():\n",
    "    rows.append({\n",
    "        'Experiment': base_exp,\n",
    "        'Seed': 'og',\n",
    "        'Œ±': data['alpha'],\n",
    "        'Œ≥': data['gamma'],\n",
    "        'Method': 'AGRE-KD' if data['use_agre'] else 'AVER',\n",
    "        'WGA (%)': data['wga'],\n",
    "        'Avg Acc (%)': data['avg_acc'],\n",
    "    })\n",
    "\n",
    "# Add seeded results\n",
    "for exp_name, data in seed_results.items():\n",
    "    base_exp = data.get('base_exp', exp_name.rsplit('_seed', 1)[0])\n",
    "    is_aver = 'aver' in base_exp.lower()\n",
    "    is_multilayer = base_exp.startswith('ml_')\n",
    "    is_disagree = 'disagree' in base_exp.lower()\n",
    "    alpha = data.get('alpha', 1.0)\n",
    "    \n",
    "    if is_multilayer:\n",
    "        method = 'Multi-Layer'\n",
    "    elif is_disagree:\n",
    "        method = 'Disagree-Weight'\n",
    "    elif is_aver:\n",
    "        method = 'AVER'\n",
    "    else:\n",
    "        method = 'AGRE-KD'\n",
    "    \n",
    "    rows.append({\n",
    "        'Experiment': base_exp,\n",
    "        'Seed': str(data.get('seed', 'N/A')),\n",
    "        'Œ±': alpha,\n",
    "        'Œ≥': data['gamma'],\n",
    "        'Method': method,\n",
    "        'WGA (%)': round(data['wga'] * 100, 2),\n",
    "        'Avg Acc (%)': round(data.get('avg_acc', 0) * 100, 2),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df['Seed'] = df['Seed'].astype(str)\n",
    "\n",
    "print(f\"\\n‚úÖ Combined {len(df)} total experiment runs\")\n",
    "print(f\"   Unique experiments: {df['Experiment'].nunique()}\")\n",
    "print(f\"   Seeds: {sorted(df['Seed'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute aggregated statistics per experiment\n",
    "agg_rows = []\n",
    "for base_exp in df['Experiment'].unique():\n",
    "    subset = df[df['Experiment'] == base_exp]\n",
    "    \n",
    "    wga_mean = subset['WGA (%)'].mean()\n",
    "    wga_std = subset['WGA (%)'].std() if len(subset) > 1 else 0\n",
    "    avg_acc_mean = subset['Avg Acc (%)'].mean()\n",
    "    n = len(subset)\n",
    "    \n",
    "    method = subset['Method'].iloc[0]\n",
    "    gamma = subset['Œ≥'].iloc[0]\n",
    "    alpha = subset['Œ±'].iloc[0]\n",
    "    \n",
    "    agg_rows.append({\n",
    "        'Experiment': base_exp,\n",
    "        'Method': method,\n",
    "        'Œ±': alpha,\n",
    "        'Œ≥': gamma,\n",
    "        'WGA_mean': wga_mean,\n",
    "        'WGA_std': wga_std,\n",
    "        'Avg_Acc': avg_acc_mean,\n",
    "        'n': n,\n",
    "    })\n",
    "\n",
    "agg_df = pd.DataFrame(agg_rows)\n",
    "print(\"\\nAggregated Results:\")\n",
    "print(agg_df.sort_values('WGA_mean', ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ Figure 1: Œ≥ Sweep Bar Chart (Main Result)\n",
    "\n",
    "Clean bar chart showing WGA vs Œ≥ (feature distillation weight) for AGRE-KD method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to AGRE-KD experiments with Œ±=1.0 (the main gamma ablation)\n",
    "# Map experiment names to gamma values\n",
    "gamma_exp_map = {\n",
    "    'baseline_agrekd': 0.00,\n",
    "    'gamma_005': 0.05,\n",
    "    'exp2_gamma01': 0.10,  # if exists\n",
    "    'exp2_gamma025': 0.25,\n",
    "    'gamma_050': 0.50,\n",
    "    'gamma_075': 0.75,\n",
    "    'gamma_100': 1.00,\n",
    "}\n",
    "\n",
    "# Get AGRE-KD data for gamma sweep\n",
    "gamma_data = agg_df[\n",
    "    (agg_df['Method'] == 'AGRE-KD') & \n",
    "    (agg_df['Œ±'] == 1.0)\n",
    "].copy()\n",
    "\n",
    "# Sort by gamma\n",
    "gamma_data = gamma_data.sort_values('Œ≥')\n",
    "\n",
    "print(\"Gamma sweep data:\")\n",
    "print(gamma_data[['Experiment', 'Œ≥', 'WGA_mean', 'WGA_std', 'n']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "gammas = gamma_data['Œ≥'].values\n",
    "means = gamma_data['WGA_mean'].values\n",
    "stds = gamma_data['WGA_std'].values\n",
    "ns = gamma_data['n'].values\n",
    "\n",
    "# Color scheme: highlight optimal (Œ≥=0.5) in green, others in blue\n",
    "# Use hatching for n=1 (single run) experiments\n",
    "colors = []\n",
    "hatches = []\n",
    "for g, n in zip(gammas, ns):\n",
    "    if g == 0.5:  # Optimal\n",
    "        colors.append('#2ecc71')  # Green\n",
    "    elif g == 0.0:  # Baseline\n",
    "        colors.append('#e74c3c')  # Red\n",
    "    else:\n",
    "        colors.append('#3498db')  # Blue\n",
    "    \n",
    "    # Hatching for single-run experiments\n",
    "    hatches.append('//' if n == 1 else '')\n",
    "\n",
    "# Create bars\n",
    "x = np.arange(len(gammas))\n",
    "bars = ax.bar(x, means, color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add hatching for n=1 experiments\n",
    "for bar, hatch in zip(bars, hatches):\n",
    "    bar.set_hatch(hatch)\n",
    "\n",
    "# Add error bars only where n > 1\n",
    "for i, (m, s, n) in enumerate(zip(means, stds, ns)):\n",
    "    if n > 1 and s > 0:\n",
    "        ax.errorbar(i, m, yerr=s, fmt='none', color='black', capsize=5, capthick=2, linewidth=2)\n",
    "\n",
    "# Add n labels above bars\n",
    "for i, (m, s, n) in enumerate(zip(means, stds, ns)):\n",
    "    y_pos = m + (s if n > 1 and s > 0 else 0) + 0.3\n",
    "    ax.annotate(f'n={n}', (i, y_pos), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add baseline reference line\n",
    "baseline_wga = gamma_data[gamma_data['Œ≥'] == 0.0]['WGA_mean'].values[0]\n",
    "ax.axhline(y=baseline_wga, color='#e74c3c', linestyle='--', linewidth=2, alpha=0.7,\n",
    "           label=f'Baseline (Œ≥=0): {baseline_wga:.1f}%')\n",
    "\n",
    "# Formatting\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{g:.2f}' for g in gammas], fontsize=12)\n",
    "ax.set_xlabel('Œ≥ (Feature Distillation Weight)', fontsize=14)\n",
    "ax.set_ylabel('Worst-Group Accuracy (%)', fontsize=14)\n",
    "ax.set_title('Effect of Feature Distillation on Worst-Group Accuracy', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Set y-axis limits to show variation clearly\n",
    "ax.set_ylim([82, 88])\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#e74c3c', edgecolor='black', label='Baseline (Œ≥=0)'),\n",
    "    Patch(facecolor='#2ecc71', edgecolor='black', label='Optimal (Œ≥=0.5)'),\n",
    "    Patch(facecolor='#3498db', edgecolor='black', label='Other Œ≥ values'),\n",
    "    Patch(facecolor='white', edgecolor='black', hatch='//', label='Single run (n=1)'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "\n",
    "# Add grid for readability\n",
    "ax.grid(True, axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "save_path = os.path.join(OUTPUT_DIR, 'gamma_sweep.png')\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"\\n‚úÖ Saved: {save_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è‚É£ Figure 2: Waterbirds Dataset Visualization\n",
    "\n",
    "2x2 grid showing the 4 groups to help readers understand spurious correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Waterbirds metadata to find example images\n",
    "metadata_path = os.path.join(DATA_DIR, 'metadata.csv')\n",
    "\n",
    "if os.path.exists(metadata_path):\n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    print(f\"‚úÖ Loaded metadata: {len(metadata)} images\")\n",
    "    print(f\"\\nColumns: {metadata.columns.tolist()}\")\n",
    "    print(f\"\\nGroup distribution (training split):\")\n",
    "    train_meta = metadata[metadata['split'] == 0]  # 0 = train\n",
    "    print(train_meta.groupby(['y', 'place']).size())\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Metadata not found at {metadata_path}\")\n",
    "    print(\"Will use placeholder visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group definitions:\n",
    "# y=0: landbird, y=1: waterbird\n",
    "# place=0: land, place=1: water\n",
    "# Group 0: landbird + land (majority)\n",
    "# Group 1: landbird + water (minority)\n",
    "# Group 2: waterbird + land (minority, hardest)\n",
    "# Group 3: waterbird + water (majority)\n",
    "\n",
    "group_info = {\n",
    "    (0, 0): {'name': 'Landbird + Land', 'type': 'majority', 'train_n': 3498},\n",
    "    (0, 1): {'name': 'Landbird + Water', 'type': 'minority', 'train_n': 184},\n",
    "    (1, 0): {'name': 'Waterbird + Land', 'type': 'minority (hardest)', 'train_n': 56},\n",
    "    (1, 1): {'name': 'Waterbird + Water', 'type': 'majority', 'train_n': 1057},\n",
    "}\n",
    "\n",
    "# Find one example image per group\n",
    "example_images = {}\n",
    "if 'metadata' in dir():\n",
    "    for (y, place), info in group_info.items():\n",
    "        subset = metadata[(metadata['y'] == y) & (metadata['place'] == place) & (metadata['split'] == 0)]\n",
    "        if len(subset) > 0:\n",
    "            # Pick a random example\n",
    "            img_filename = subset.sample(1)['img_filename'].values[0]\n",
    "            img_path = os.path.join(DATA_DIR, img_filename)\n",
    "            if os.path.exists(img_path):\n",
    "                example_images[(y, place)] = img_path\n",
    "                print(f\"Group ({y}, {place}): {img_filename}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(example_images)} example images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2x2 visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Layout: rows = bird type (landbird, waterbird), cols = background (land, water)\n",
    "positions = {\n",
    "    (0, 0): (0, 0),  # landbird + land -> top-left\n",
    "    (0, 1): (0, 1),  # landbird + water -> top-right\n",
    "    (1, 0): (1, 0),  # waterbird + land -> bottom-left\n",
    "    (1, 1): (1, 1),  # waterbird + water -> bottom-right\n",
    "}\n",
    "\n",
    "for (y, place), (row, col) in positions.items():\n",
    "    ax = axes[row, col]\n",
    "    info = group_info[(y, place)]\n",
    "    \n",
    "    # Load and display image if available\n",
    "    if (y, place) in example_images:\n",
    "        img = Image.open(example_images[(y, place)])\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        # Placeholder\n",
    "        ax.text(0.5, 0.5, 'Image\\nNot Found', ha='center', va='center', fontsize=14,\n",
    "                transform=ax.transAxes)\n",
    "        ax.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Title with group info\n",
    "    pct = info['train_n'] / 4795 * 100\n",
    "    title = f\"{info['name']}\\n(n={info['train_n']}, {pct:.1f}%)\"\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Highlight minority groups (especially the hardest one)\n",
    "    if info['type'] == 'minority (hardest)':\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('#e74c3c')\n",
    "            spine.set_linewidth(4)\n",
    "    elif info['type'] == 'minority':\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('#f39c12')\n",
    "            spine.set_linewidth(3)\n",
    "    else:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('#2ecc71')\n",
    "            spine.set_linewidth(2)\n",
    "\n",
    "# Add row/column labels\n",
    "fig.text(0.02, 0.75, 'Landbird', va='center', ha='center', rotation=90, fontsize=14, fontweight='bold')\n",
    "fig.text(0.02, 0.25, 'Waterbird', va='center', ha='center', rotation=90, fontsize=14, fontweight='bold')\n",
    "fig.text(0.3, 0.98, 'Land Background', va='center', ha='center', fontsize=14, fontweight='bold')\n",
    "fig.text(0.7, 0.98, 'Water Background', va='center', ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add legend for border colors\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='white', edgecolor='#2ecc71', linewidth=3, label='Majority group'),\n",
    "    Patch(facecolor='white', edgecolor='#f39c12', linewidth=3, label='Minority group'),\n",
    "    Patch(facecolor='white', edgecolor='#e74c3c', linewidth=4, label='Hardest minority (WGA target)'),\n",
    "]\n",
    "fig.legend(handles=legend_elements, loc='lower center', ncol=3, fontsize=11, bbox_to_anchor=(0.5, -0.02))\n",
    "\n",
    "plt.suptitle('Waterbirds Dataset: Spurious Correlation Between Bird Type and Background', \n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08)\n",
    "\n",
    "# Save figure\n",
    "save_path = os.path.join(OUTPUT_DIR, 'waterbirds_groups.png')\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"\\n‚úÖ Saved: {save_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ (Optional) AGRE-KD vs AVER Comparison\n",
    "\n",
    "Line plot comparing gradient-based weighting (AGRE-KD) vs simple averaging (AVER) across Œ≥ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AGRE-KD and AVER data\n",
    "agrekd_data = agg_df[(agg_df['Method'] == 'AGRE-KD') & (agg_df['Œ±'] == 1.0)].sort_values('Œ≥')\n",
    "aver_data = agg_df[(agg_df['Method'] == 'AVER') & (agg_df['Œ±'] == 1.0)].sort_values('Œ≥')\n",
    "\n",
    "print(\"AGRE-KD data points:\")\n",
    "print(agrekd_data[['Œ≥', 'WGA_mean', 'WGA_std', 'n']].to_string(index=False))\n",
    "print(\"\\nAVER data points:\")\n",
    "print(aver_data[['Œ≥', 'WGA_mean', 'WGA_std', 'n']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# AGRE-KD line\n",
    "ax.errorbar(agrekd_data['Œ≥'], agrekd_data['WGA_mean'], \n",
    "            yerr=agrekd_data['WGA_std'].where(agrekd_data['n'] > 1, 0),\n",
    "            fmt='o-', linewidth=2.5, markersize=10, capsize=5, capthick=2,\n",
    "            color='#3498db', label='AGRE-KD (gradient weighting)')\n",
    "\n",
    "# AVER line\n",
    "if len(aver_data) > 0:\n",
    "    ax.errorbar(aver_data['Œ≥'], aver_data['WGA_mean'],\n",
    "                yerr=aver_data['WGA_std'].where(aver_data['n'] > 1, 0),\n",
    "                fmt='s--', linewidth=2.5, markersize=10, capsize=5, capthick=2,\n",
    "                color='#e67e22', label='AVER (simple averaging)')\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Œ≥ (Feature Distillation Weight)', fontsize=14)\n",
    "ax.set_ylabel('Worst-Group Accuracy (%)', fontsize=14)\n",
    "ax.set_title('AGRE-KD vs AVER: Gradient Weighting Improves WGA Across All Œ≥', fontsize=16, fontweight='bold')\n",
    "ax.legend(fontsize=12, loc='lower right')\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Set reasonable y-limits\n",
    "ax.set_ylim([82, 88])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "save_path = os.path.join(OUTPUT_DIR, 'agrekd_vs_aver.png')\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"\\n‚úÖ Saved: {save_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è‚É£ Figure 3: Summary Results Table (Heatmap Style)\n",
    "\n",
    "Publication-quality table showing all methods ranked by WGA, with both WGA and Avg Acc columns.\n",
    "Color-coded cells highlight best/worst results at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Publication-Quality Results Table (Heatmap Style)\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for the summary table\n",
    "# We need: Rank, Method, Œ±, Œ≥, WGA (%), Avg Acc (%)\n",
    "\n",
    "# Recompute aggregated stats including Avg Acc std\n",
    "table_rows = []\n",
    "for base_exp in df['Experiment'].unique():\n",
    "    subset = df[df['Experiment'] == base_exp]\n",
    "    \n",
    "    wga_mean = subset['WGA (%)'].mean()\n",
    "    wga_std = subset['WGA (%)'].std() if len(subset) > 1 else 0\n",
    "    avg_acc_mean = subset['Avg Acc (%)'].mean()\n",
    "    avg_acc_std = subset['Avg Acc (%)'].std() if len(subset) > 1 else 0\n",
    "    n = len(subset)\n",
    "    \n",
    "    method = subset['Method'].iloc[0]\n",
    "    gamma = subset['Œ≥'].iloc[0]\n",
    "    alpha = subset['Œ±'].iloc[0]\n",
    "    \n",
    "    table_rows.append({\n",
    "        'Experiment': base_exp,\n",
    "        'Method': method,\n",
    "        'Œ±': alpha,\n",
    "        'Œ≥': gamma,\n",
    "        'WGA_mean': wga_mean,\n",
    "        'WGA_std': wga_std,\n",
    "        'Avg_Acc_mean': avg_acc_mean,\n",
    "        'Avg_Acc_std': avg_acc_std,\n",
    "        'n': n,\n",
    "    })\n",
    "\n",
    "table_df = pd.DataFrame(table_rows)\n",
    "table_df = table_df.sort_values('WGA_mean', ascending=False).reset_index(drop=True)\n",
    "table_df['Rank'] = range(1, len(table_df) + 1)\n",
    "\n",
    "# Format strings for display\n",
    "def format_metric(mean, std, n):\n",
    "    if n > 1 and std > 0:\n",
    "        return f\"{mean:.2f} ¬± {std:.2f}\"\n",
    "    else:\n",
    "        return f\"{mean:.2f}\"\n",
    "\n",
    "table_df['WGA (%)'] = table_df.apply(lambda r: format_metric(r['WGA_mean'], r['WGA_std'], r['n']), axis=1)\n",
    "table_df['Avg Acc (%)'] = table_df.apply(lambda r: format_metric(r['Avg_Acc_mean'], r['Avg_Acc_std'], r['n']), axis=1)\n",
    "\n",
    "print(\"Summary Table Data:\")\n",
    "print(table_df[['Rank', 'Method', 'Œ±', 'Œ≥', 'WGA (%)', 'Avg Acc (%)', 'n']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Create Publication-Quality Table Figure\n",
    "# ============================================================\n",
    "\n",
    "# Select columns for display\n",
    "display_cols = ['Rank', 'Method', 'Œ±', 'Œ≥', 'WGA (%)', 'Avg Acc (%)', 'n']\n",
    "display_df = table_df[display_cols].copy()\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(12, 0.5 * len(display_df) + 1.5))\n",
    "ax.axis('off')\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(\n",
    "    cellText=display_df.values,\n",
    "    colLabels=display_df.columns,\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    colColours=['#4a90d9'] * len(display_df.columns),  # Header color\n",
    ")\n",
    "\n",
    "# Style the table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.2, 1.8)  # Scale width and height\n",
    "\n",
    "# Color-code cells based on WGA values\n",
    "# Get WGA mean values for coloring\n",
    "wga_means = table_df['WGA_mean'].values\n",
    "wga_min, wga_max = wga_means.min(), wga_means.max()\n",
    "\n",
    "# Create colormap (red=low, white=mid, green=high)\n",
    "cmap = plt.cm.RdYlGn\n",
    "\n",
    "# Style header row\n",
    "for j, col in enumerate(display_df.columns):\n",
    "    cell = table[(0, j)]\n",
    "    cell.set_text_props(weight='bold', color='white')\n",
    "    cell.set_facecolor('#2c3e50')\n",
    "\n",
    "# Style data rows with conditional formatting\n",
    "for i in range(len(display_df)):\n",
    "    # Normalize WGA for color\n",
    "    wga_norm = (wga_means[i] - wga_min) / (wga_max - wga_min) if wga_max > wga_min else 0.5\n",
    "    row_color = cmap(0.3 + 0.5 * wga_norm)  # Map to middle range of colormap\n",
    "    \n",
    "    for j, col in enumerate(display_df.columns):\n",
    "        cell = table[(i + 1, j)]\n",
    "        \n",
    "        # Highlight WGA column with gradient\n",
    "        if col == 'WGA (%)':\n",
    "            cell.set_facecolor(cmap(0.2 + 0.6 * wga_norm))\n",
    "            if wga_norm > 0.7:  # Best results get bold\n",
    "                cell.set_text_props(weight='bold')\n",
    "        # Highlight best row (rank 1)\n",
    "        elif i == 0:\n",
    "            cell.set_facecolor('#d5f5e3')  # Light green\n",
    "            cell.set_text_props(weight='bold')\n",
    "        # Alternating row colors for readability\n",
    "        elif i % 2 == 0:\n",
    "            cell.set_facecolor('#f8f9fa')\n",
    "        else:\n",
    "            cell.set_facecolor('#ffffff')\n",
    "\n",
    "# Add title\n",
    "plt.title('Summary of Results: Methods Ranked by Worst-Group Accuracy', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "save_path = os.path.join(OUTPUT_DIR, 'results_table.png')\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "print(f\"\\n‚úÖ Saved: {save_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Alternative: Seaborn Heatmap Style (More Visual)\n",
    "# ============================================================\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a cleaner version with just the key metrics as a heatmap\n",
    "# Rows = methods, Columns = metrics (WGA, Avg Acc)\n",
    "\n",
    "# Prepare heatmap data\n",
    "heatmap_data = table_df[['Method', 'Œ≥', 'WGA_mean', 'Avg_Acc_mean']].copy()\n",
    "heatmap_data['Label'] = heatmap_data.apply(\n",
    "    lambda r: f\"{r['Method']}\\n(Œ≥={r['Œ≥']:.2f})\" if r['Œ≥'] > 0 else f\"{r['Method']}\\n(baseline)\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create pivot for heatmap\n",
    "metrics_df = heatmap_data[['Label', 'WGA_mean', 'Avg_Acc_mean']].set_index('Label')\n",
    "metrics_df.columns = ['WGA (%)', 'Avg Acc (%)']\n",
    "\n",
    "# Create figure with two subplots - one for each metric\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 0.6 * len(metrics_df) + 2))\n",
    "\n",
    "# WGA Heatmap (horizontal bar style)\n",
    "ax1 = axes[0]\n",
    "colors_wga = sns.color_palette(\"RdYlGn\", n_colors=len(metrics_df))\n",
    "sorted_idx = metrics_df['WGA (%)'].argsort()\n",
    "y_pos = np.arange(len(metrics_df))\n",
    "\n",
    "bars1 = ax1.barh(y_pos, metrics_df['WGA (%)'].values[sorted_idx], \n",
    "                  color=[colors_wga[i] for i in range(len(sorted_idx))])\n",
    "ax1.set_yticks(y_pos)\n",
    "ax1.set_yticklabels(metrics_df.index[sorted_idx], fontsize=10)\n",
    "ax1.set_xlabel('Worst-Group Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('WGA by Method', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlim([80, 88])\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, val) in enumerate(zip(sorted_idx, metrics_df['WGA (%)'].values[sorted_idx])):\n",
    "    ax1.text(val + 0.1, i, f'{val:.1f}%', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Avg Acc Heatmap\n",
    "ax2 = axes[1]\n",
    "colors_avg = sns.color_palette(\"Blues\", n_colors=len(metrics_df))\n",
    "sorted_idx_avg = metrics_df['Avg Acc (%)'].argsort()\n",
    "\n",
    "bars2 = ax2.barh(y_pos, metrics_df['Avg Acc (%)'].values[sorted_idx_avg],\n",
    "                  color=[colors_avg[i] for i in range(len(sorted_idx_avg))])\n",
    "ax2.set_yticks(y_pos)\n",
    "ax2.set_yticklabels(metrics_df.index[sorted_idx_avg], fontsize=10)\n",
    "ax2.set_xlabel('Average Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Avg Acc by Method', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlim([88, 95])\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, val) in enumerate(zip(sorted_idx_avg, metrics_df['Avg Acc (%)'].values[sorted_idx_avg])):\n",
    "    ax2.text(val + 0.1, i, f'{val:.1f}%', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Method Comparison: WGA vs Average Accuracy', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "save_path = os.path.join(OUTPUT_DIR, 'results_bars.png')\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"\\n‚úÖ Saved: {save_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CONSOLIDATED RESULTS TABLE (One Row Per Method)\n# Clean, publication-ready table for the report\n# ============================================================\n\n# Define method categories and their best configurations\n# We'll pick the best Œ≥ for each method type\n\nmethod_categories = {\n    'AGRE-KD + Features': {'method': 'AGRE-KD', 'alpha': 1.0, 'gamma_min': 0.01, 'gamma_max': 1.0},\n    'AGRE-KD Baseline': {'method': 'AGRE-KD', 'alpha': 1.0, 'gamma_min': 0.0, 'gamma_max': 0.0},\n    'Disagree-Weight': {'method': 'Disagree-Weight', 'alpha': 1.0, 'gamma_min': 0.0, 'gamma_max': 1.0},\n    'Multi-Layer': {'method': 'Multi-Layer', 'alpha': 1.0, 'gamma_min': 0.0, 'gamma_max': 1.0},\n    'AVER + Features': {'method': 'AVER', 'alpha': 1.0, 'gamma_min': 0.01, 'gamma_max': 1.0},\n    'AVER Baseline': {'method': 'AVER', 'alpha': 1.0, 'gamma_min': 0.0, 'gamma_max': 0.0},\n    'Combined (Œ±<1)': {'method': 'AGRE-KD', 'alpha_max': 0.99, 'gamma_min': 0.0, 'gamma_max': 1.0},\n}\n\nconsolidated_rows = []\n\nfor category_name, filters in method_categories.items():\n    # Filter table_df based on category\n    mask = (table_df['Method'] == filters['method'])\n    \n    if 'alpha' in filters:\n        mask &= (table_df['Œ±'] == filters['alpha'])\n    if 'alpha_max' in filters:\n        mask &= (table_df['Œ±'] < filters['alpha_max'])\n    if 'gamma_min' in filters:\n        mask &= (table_df['Œ≥'] >= filters['gamma_min'])\n    if 'gamma_max' in filters:\n        mask &= (table_df['Œ≥'] <= filters['gamma_max'])\n    \n    subset = table_df[mask]\n    \n    if len(subset) == 0:\n        continue\n    \n    # Get the best result (highest WGA) for this category\n    best_row = subset.loc[subset['WGA_mean'].idxmax()]\n    \n    consolidated_rows.append({\n        'Method': category_name,\n        'Best Œ≥': best_row['Œ≥'],\n        'WGA_mean': best_row['WGA_mean'],\n        'WGA_std': best_row['WGA_std'],\n        'Avg_Acc_mean': best_row['Avg_Acc_mean'],\n        'Avg_Acc_std': best_row['Avg_Acc_std'],\n        'n': best_row['n'],\n        'is_baseline': 'Baseline' in category_name,\n    })\n\nconsolidated_df = pd.DataFrame(consolidated_rows)\nconsolidated_df = consolidated_df.sort_values('WGA_mean', ascending=False).reset_index(drop=True)\n\n# Format display strings\ndef format_metric(mean, std, n):\n    if n > 1 and std > 0:\n        return f\"{mean:.2f} ¬± {std:.2f}\"\n    else:\n        return f\"{mean:.2f}\"\n\nconsolidated_df['WGA (%)'] = consolidated_df.apply(\n    lambda r: format_metric(r['WGA_mean'], r['WGA_std'], r['n']), axis=1)\nconsolidated_df['Avg Acc (%)'] = consolidated_df.apply(\n    lambda r: format_metric(r['Avg_Acc_mean'], r['Avg_Acc_std'], r['n']), axis=1)\n\nprint(\"Consolidated Results (one row per method):\")\nprint(consolidated_df[['Method', 'Best Œ≥', 'WGA (%)', 'Avg Acc (%)', 'n']].to_string(index=False))\n\n# ============================================================\n# Create the consolidated table figure (compact, no legend)\n# ============================================================\ndisplay_cols = ['Method', 'Best Œ≥', 'WGA (%)', 'Avg Acc (%)', 'n']\ndisplay_df = consolidated_df[display_cols].copy()\n\n# Create figure - compact sizing, no extra space for legend\nfig, ax = plt.subplots(figsize=(10, 0.5 * len(display_df) + 0.8))\nax.axis('off')\n\n# Create the table\ntable = ax.table(\n    cellText=display_df.values,\n    colLabels=display_df.columns,\n    cellLoc='center',\n    loc='center',\n)\n\n# Style the table\ntable.auto_set_font_size(False)\ntable.set_fontsize(11)\ntable.scale(1.3, 1.8)\n\n# Get WGA values for color coding\nwga_means = consolidated_df['WGA_mean'].values\nwga_min, wga_max = wga_means.min(), wga_means.max()\ncmap = plt.cm.RdYlGn\n\n# Style header row\nfor j, col in enumerate(display_df.columns):\n    cell = table[(0, j)]\n    cell.set_text_props(weight='bold', color='white', fontsize=11)\n    cell.set_facecolor('#2c3e50')\n\n# Style data rows\nfor i in range(len(display_df)):\n    is_baseline = consolidated_df.iloc[i]['is_baseline']\n    is_best = (i == 0)  # First row after sorting is best\n    wga_norm = (wga_means[i] - wga_min) / (wga_max - wga_min) if wga_max > wga_min else 0.5\n    \n    for j, col in enumerate(display_df.columns):\n        cell = table[(i + 1, j)]\n        \n        if col == 'WGA (%)':\n            # WGA column gets gradient color\n            cell.set_facecolor(cmap(0.25 + 0.5 * wga_norm))\n            if is_best:\n                cell.set_text_props(weight='bold', fontsize=11)\n            else:\n                cell.set_text_props(fontsize=11)\n        elif is_best:\n            # Best row (rank 1) - light green\n            cell.set_facecolor('#d5f5e3')\n            cell.set_text_props(weight='bold', fontsize=11)\n        elif is_baseline:\n            # Baseline rows - light blue\n            cell.set_facecolor('#e8f4f8')\n            cell.set_text_props(fontsize=11)\n        elif i % 2 == 0:\n            cell.set_facecolor('#f8f9fa')\n            cell.set_text_props(fontsize=11)\n        else:\n            cell.set_facecolor('#ffffff')\n            cell.set_text_props(fontsize=11)\n\n# No title - let the report caption handle it\n# No legend - colors are self-explanatory\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.95, bottom=0.05)\n\n# Save figure\nsave_path = os.path.join(OUTPUT_DIR, 'results_table_consolidated.png')\nplt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none', pad_inches=0.1)\nprint(f\"\\n‚úÖ Saved: {save_path}\")\n\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## 7Ô∏è‚É£ Refined Results Analysis (Full Statistics)\n\nComplete aggregated results with WGA ¬± std AND Avg Acc ¬± std for all experiments.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# REFINED AGGREGATED RESULTS - Full Statistics\n# WGA ¬± std AND Avg Acc ¬± std for all experiments\n# ============================================================\n\n# Ensure df is properly loaded (re-run if needed)\nprint(\"=\" * 100)\nprint(\"ALL EXPERIMENT RUNS (raw data)\")\nprint(\"=\" * 100)\n\n# Assign categories for organization\ndef get_category(row):\n    if row['Method'] == 'Multi-Layer':\n        return '6. Multi-Layer'\n    if row['Method'] == 'Disagree-Weight':\n        return '5. Disagree Weighting'\n    if row['Œ±'] < 1.0:\n        return '4. Combined (Œ±<1)'\n    if row['Method'] == 'AVER':\n        if row['Œ≥'] == 0:\n            return '1a. Baseline (AVER)'\n        return '3. Feature Dist (AVER)'\n    else:  # AGRE-KD\n        if row['Œ≥'] == 0:\n            return '1b. Baseline (AGRE-KD)'\n        return '2. Feature Dist (AGRE-KD)'\n\ndf['Category'] = df.apply(get_category, axis=1)\n\n# Sort by category, then by experiment, then by seed\ndf_sorted = df.sort_values(['Category', 'Experiment', 'Seed'], ascending=[True, True, True])\n\ndisplay_cols = ['Category', 'Experiment', 'Seed', 'Œ±', 'Œ≥', 'Method', 'WGA (%)', 'Avg Acc (%)']\nprint(df_sorted[display_cols].to_string(index=False))\n\n# ============================================================\n# AGGREGATED RESULTS WITH FULL STATISTICS\n# ============================================================\nprint(\"\\n\" + \"=\" * 100)\nprint(\"AGGREGATED RESULTS BY EXPERIMENT (with Avg Acc ¬± std)\")\nprint(\"=\" * 100)\n\nagg_full_rows = []\nfor base_exp in df['Experiment'].unique():\n    subset = df[df['Experiment'] == base_exp]\n    \n    # WGA statistics\n    wga_mean = subset['WGA (%)'].mean()\n    wga_std = subset['WGA (%)'].std() if len(subset) > 1 else 0\n    \n    # Avg Acc statistics\n    avg_acc_mean = subset['Avg Acc (%)'].mean()\n    avg_acc_std = subset['Avg Acc (%)'].std() if len(subset) > 1 else 0\n    \n    n = len(subset)\n    \n    # Track which seeds we have\n    seeds_list = sorted([str(s) for s in subset['Seed'].unique()])\n    seeds_str = ','.join(seeds_list)\n    \n    method = subset['Method'].iloc[0]\n    gamma = subset['Œ≥'].iloc[0]\n    alpha = subset['Œ±'].iloc[0]\n    category = subset['Category'].iloc[0]\n    \n    # Format strings\n    if wga_std > 0:\n        wga_str = f\"{wga_mean:.2f} ¬± {wga_std:.2f}\"\n    else:\n        wga_str = f\"{wga_mean:.2f}\"\n    \n    if avg_acc_std > 0:\n        avg_acc_str = f\"{avg_acc_mean:.2f} ¬± {avg_acc_std:.2f}\"\n    else:\n        avg_acc_str = f\"{avg_acc_mean:.2f}\"\n    \n    agg_full_rows.append({\n        'Category': category,\n        'Experiment': base_exp,\n        'Method': method,\n        'Œ±': alpha,\n        'Œ≥': gamma,\n        'WGA (%)': wga_str,\n        'Avg Acc (%)': avg_acc_str,\n        'n': n,\n        'Seeds': seeds_str,\n        '_wga_mean': wga_mean,\n        '_wga_std': wga_std,\n        '_avg_acc_mean': avg_acc_mean,\n        '_avg_acc_std': avg_acc_std,\n    })\n\nagg_full_df = pd.DataFrame(agg_full_rows)\n\n# Show by category\nprint(\"\\n--- Grouped by Category ---\")\nagg_by_cat = agg_full_df.sort_values(['Category', '_wga_mean'], ascending=[True, False])\nprint(agg_by_cat[['Category', 'Experiment', 'Method', 'Œ±', 'Œ≥', 'WGA (%)', 'Avg Acc (%)', 'n', 'Seeds']].to_string(index=False))\n\n# Ranked by WGA\nprint(\"\\n\" + \"-\" * 100)\nprint(\"--- Ranked by WGA ---\")\nagg_by_wga = agg_full_df.sort_values('_wga_mean', ascending=False).reset_index(drop=True)\nagg_by_wga['Rank'] = range(1, len(agg_by_wga) + 1)\nprint(agg_by_wga[['Rank', 'Experiment', 'Method', 'Œ±', 'Œ≥', 'WGA (%)', 'Avg Acc (%)', 'n', 'Seeds']].to_string(index=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# KEY FINDINGS SUMMARY\n# ============================================================\nprint(\"\\n\" + \"=\" * 100)\nprint(\"KEY FINDINGS\")\nprint(\"=\" * 100)\n\n# Best overall\nbest = agg_full_df.loc[agg_full_df['_wga_mean'].idxmax()]\nprint(f\"\\nüèÜ Best overall: {best['Experiment']} ({best['Method']}, Œ±={best['Œ±']}, Œ≥={best['Œ≥']})\")\nprint(f\"   WGA: {best['WGA (%)']} (n={best['n']}, seeds: {best['Seeds']})\")\nprint(f\"   Avg Acc: {best['Avg Acc (%)']}\")\n\n# Best AGRE-KD with features\nagre_features = agg_full_df[(agg_full_df['Method'] == 'AGRE-KD') & (agg_full_df['_wga_mean'] > 0) & (agg_full_df['Œ≥'] > 0)]\nif len(agre_features) > 0:\n    best_agre = agre_features.loc[agre_features['_wga_mean'].idxmax()]\n    print(f\"\\nüìä Best AGRE-KD + Features: {best_agre['Experiment']} (Œ≥={best_agre['Œ≥']})\")\n    print(f\"   WGA: {best_agre['WGA (%)']} | Avg Acc: {best_agre['Avg Acc (%)']}\")\n\n# Baseline comparison\nbaseline = agg_full_df[agg_full_df['Experiment'] == 'baseline_agrekd']\nif len(baseline) > 0:\n    baseline_row = baseline.iloc[0]\n    print(f\"\\nüìà AGRE-KD Baseline (Œ≥=0):\")\n    print(f\"   WGA: {baseline_row['WGA (%)']} | Avg Acc: {baseline_row['Avg Acc (%)']}\")\n    \n    # Improvement over baseline\n    if len(agre_features) > 0:\n        improvement = agre_features['_wga_mean'].max() - baseline_row['_wga_mean']\n        print(f\"   Best improvement: +{improvement:.2f}%\")\n\n# AVER vs AGRE-KD comparison\naver_baseline = agg_full_df[agg_full_df['Experiment'] == 'aver_baseline']\nif len(aver_baseline) > 0 and len(baseline) > 0:\n    aver_row = aver_baseline.iloc[0]\n    agre_row = baseline.iloc[0]\n    diff = agre_row['_wga_mean'] - aver_row['_wga_mean']\n    print(f\"\\nüîÑ AGRE-KD vs AVER Baseline:\")\n    print(f\"   AGRE-KD: {agre_row['WGA (%)']} | AVER: {aver_row['WGA (%)']} | Diff: {diff:+.2f}%\")\n\nprint(\"\\n\" + \"=\" * 100)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# SEED VARIANCE ANALYSIS BY EXPERIMENT\n# Shows individual seed results + statistics\n# ============================================================\nprint(\"\\n\" + \"=\" * 100)\nprint(\"SEED VARIANCE ANALYSIS BY EXPERIMENT\")\nprint(\"=\" * 100)\n\nfor exp in sorted(df['Experiment'].unique()):\n    subset = df[df['Experiment'] == exp]\n    if len(subset) > 0:\n        wgas = subset['WGA (%)'].values\n        avg_accs = subset['Avg Acc (%)'].values\n        seeds_list = subset['Seed'].values\n        gamma = subset['Œ≥'].iloc[0]\n        method = subset['Method'].iloc[0]\n        \n        print(f\"\\n{exp} ({method}, Œ≥={gamma}):\")\n        for seed, wga, acc in zip(seeds_list, wgas, avg_accs):\n            marker = \" (og)\" if seed == 'og' else \"\"\n            print(f\"  Seed {seed}{marker}: WGA={wga:.2f}%, Avg Acc={acc:.2f}%\")\n        \n        if len(wgas) > 1:\n            print(f\"  ‚Üí WGA:     Mean={np.mean(wgas):.2f}% | Std={np.std(wgas):.2f}% | Range={np.max(wgas)-np.min(wgas):.2f}%\")\n            print(f\"  ‚Üí Avg Acc: Mean={np.mean(avg_accs):.2f}% | Std={np.std(avg_accs):.2f}% | Range={np.max(avg_accs)-np.min(avg_accs):.2f}%\")\n\nprint(\"\\n\" + \"=\" * 100)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# UPDATED CONSOLIDATED TABLE FOR REPORT\n# One row per method category with full WGA and Avg Acc ¬± std\n# ============================================================\n\n# Use agg_full_df which has proper statistics\nmethod_categories = {\n    'AGRE-KD + Features': {'method': 'AGRE-KD', 'alpha': 1.0, 'gamma_min': 0.01, 'gamma_max': 1.0},\n    'AGRE-KD Baseline': {'method': 'AGRE-KD', 'alpha': 1.0, 'gamma_min': 0.0, 'gamma_max': 0.0},\n    'Disagree-Weight': {'method': 'Disagree-Weight', 'alpha': 1.0, 'gamma_min': 0.0, 'gamma_max': 1.0},\n    'Multi-Layer': {'method': 'Multi-Layer', 'alpha': 1.0, 'gamma_min': 0.0, 'gamma_max': 1.0},\n    'AVER + Features': {'method': 'AVER', 'alpha': 1.0, 'gamma_min': 0.01, 'gamma_max': 1.0},\n    'AVER Baseline': {'method': 'AVER', 'alpha': 1.0, 'gamma_min': 0.0, 'gamma_max': 0.0},\n    'Combined (Œ±<1)': {'method': 'AGRE-KD', 'alpha_max': 0.99, 'gamma_min': 0.0, 'gamma_max': 1.0},\n}\n\nfinal_consolidated_rows = []\n\nfor category_name, filters in method_categories.items():\n    # Filter agg_full_df based on category\n    mask = (agg_full_df['Method'] == filters['method'])\n    \n    if 'alpha' in filters:\n        mask &= (agg_full_df['Œ±'] == filters['alpha'])\n    if 'alpha_max' in filters:\n        mask &= (agg_full_df['Œ±'] < filters['alpha_max'])\n    if 'gamma_min' in filters:\n        mask &= (agg_full_df['Œ≥'] >= filters['gamma_min'])\n    if 'gamma_max' in filters:\n        mask &= (agg_full_df['Œ≥'] <= filters['gamma_max'])\n    \n    subset = agg_full_df[mask]\n    \n    if len(subset) == 0:\n        continue\n    \n    # Get the best result (highest WGA) for this category\n    best_row = subset.loc[subset['_wga_mean'].idxmax()]\n    \n    final_consolidated_rows.append({\n        'Method': category_name,\n        'Best Œ≥': best_row['Œ≥'],\n        'WGA (%)': best_row['WGA (%)'],  # Already formatted with ¬± std\n        'Avg Acc (%)': best_row['Avg Acc (%)'],  # Already formatted with ¬± std\n        'n': best_row['n'],\n        '_wga_mean': best_row['_wga_mean'],\n        '_avg_acc_mean': best_row['_avg_acc_mean'],\n        'is_baseline': 'Baseline' in category_name,\n    })\n\nfinal_consolidated_df = pd.DataFrame(final_consolidated_rows)\nfinal_consolidated_df = final_consolidated_df.sort_values('_wga_mean', ascending=False).reset_index(drop=True)\n\nprint(\"\\n\" + \"=\" * 100)\nprint(\"FINAL CONSOLIDATED TABLE FOR REPORT\")\nprint(\"=\" * 100)\nprint(final_consolidated_df[['Method', 'Best Œ≥', 'WGA (%)', 'Avg Acc (%)', 'n']].to_string(index=False))\n\n# ============================================================\n# Generate the figure\n# ============================================================\ndisplay_cols = ['Method', 'Best Œ≥', 'WGA (%)', 'Avg Acc (%)', 'n']\ndisplay_df = final_consolidated_df[display_cols].copy()\n\nfig, ax = plt.subplots(figsize=(10, 0.5 * len(display_df) + 0.8))\nax.axis('off')\n\ntable = ax.table(\n    cellText=display_df.values,\n    colLabels=display_df.columns,\n    cellLoc='center',\n    loc='center',\n)\n\ntable.auto_set_font_size(False)\ntable.set_fontsize(11)\ntable.scale(1.3, 1.8)\n\nwga_means = final_consolidated_df['_wga_mean'].values\nwga_min, wga_max = wga_means.min(), wga_means.max()\ncmap = plt.cm.RdYlGn\n\n# Style header row\nfor j, col in enumerate(display_df.columns):\n    cell = table[(0, j)]\n    cell.set_text_props(weight='bold', color='white', fontsize=11)\n    cell.set_facecolor('#2c3e50')\n\n# Style data rows\nfor i in range(len(display_df)):\n    is_baseline = final_consolidated_df.iloc[i]['is_baseline']\n    is_best = (i == 0)\n    wga_norm = (wga_means[i] - wga_min) / (wga_max - wga_min) if wga_max > wga_min else 0.5\n    \n    for j, col in enumerate(display_df.columns):\n        cell = table[(i + 1, j)]\n        \n        if col == 'WGA (%)':\n            cell.set_facecolor(cmap(0.25 + 0.5 * wga_norm))\n            if is_best:\n                cell.set_text_props(weight='bold', fontsize=11)\n            else:\n                cell.set_text_props(fontsize=11)\n        elif is_best:\n            cell.set_facecolor('#d5f5e3')\n            cell.set_text_props(weight='bold', fontsize=11)\n        elif is_baseline:\n            cell.set_facecolor('#e8f4f8')\n            cell.set_text_props(fontsize=11)\n        elif i % 2 == 0:\n            cell.set_facecolor('#f8f9fa')\n            cell.set_text_props(fontsize=11)\n        else:\n            cell.set_facecolor('#ffffff')\n            cell.set_text_props(fontsize=11)\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.95, bottom=0.05)\n\nsave_path = os.path.join(OUTPUT_DIR, 'results_table_consolidated.png')\nplt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none', pad_inches=0.1)\nprint(f\"\\n‚úÖ Saved: {save_path}\")\n\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}