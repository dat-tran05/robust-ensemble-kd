{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Ensemble Knowledge Distillation Experiments\n",
    "\n",
    "This notebook runs all experiments for extending AGRE-KD with:\n",
    "1. **Experiment 1**: Class labels (α < 1, γ = 0)\n",
    "2. **Experiment 2**: Feature distillation (α = 1, γ > 0)\n",
    "3. **Experiment 3**: Combined (α < 1, γ > 0)\n",
    "\n",
    "**Resume Support**: Each experiment checkpoints every 5 epochs. If Colab disconnects, re-run cells 1-5 then resume the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q wilds tqdm\n",
    "\n",
    "# Verify GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURE THESE PATHS\n",
    "# ============================================================\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/robust-ensemble-kd'\n",
    "CODE_DIR = f'{DRIVE_ROOT}/light-code'\n",
    "DATA_DIR = f'{DRIVE_ROOT}/data/waterbirds_v1.0'\n",
    "TEACHER_DIR = f'{DRIVE_ROOT}/teacher_checkpoints'\n",
    "CHECKPOINT_DIR = f'{DRIVE_ROOT}/checkpoints'\n",
    "LOG_DIR = f'{DRIVE_ROOT}/logs'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# Add code to path\n",
    "sys.path.insert(0, CODE_DIR)\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"Checking paths...\")\n",
    "assert os.path.exists(CODE_DIR), f\"Code not found: {CODE_DIR}\"\n",
    "assert os.path.exists(DATA_DIR), f\"Data not found: {DATA_DIR}\"\n",
    "assert os.path.exists(TEACHER_DIR), f\"Teachers not found: {TEACHER_DIR}\"\n",
    "print(\"All paths verified!\")\n",
    "\n",
    "# List available checkpoints\n",
    "ckpts = [f for f in os.listdir(TEACHER_DIR) if f.endswith('.pt') or f.endswith('.pth')]\n",
    "print(f\"\\nFound {len(ckpts)} teacher checkpoints: {ckpts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_waterbirds_loaders\n",
    "\n",
    "# Load data\n",
    "print(\"Loading Waterbirds dataset...\")\n",
    "loaders = get_waterbirds_loaders(\n",
    "    root_dir=DATA_DIR,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "# Quick verification\n",
    "batch = next(iter(loaders['train']))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  Images: {batch['image'].shape}\")\n",
    "print(f\"  Labels: {batch['label'].shape}\")\n",
    "print(f\"  Groups: {batch['group'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Load Teachers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_teacher_model, load_dfr_checkpoint, load_teachers_from_dir\n",
    "\n",
    "# Option 1: Load all teachers from directory\n",
    "print(\"Loading teacher models...\")\n",
    "teachers = load_teachers_from_dir(\n",
    "    checkpoint_dir=TEACHER_DIR,\n",
    "    model_fn=lambda: get_teacher_model('resnet50', num_classes=2, pretrained=False),\n",
    "    num_teachers=5,  # Adjust based on how many you have\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded {len(teachers)} teachers\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_batch = batch['image'][:4].cuda()\n",
    "    test_out = teachers[0](test_batch)\n",
    "    print(f\"Test forward pass: {test_out.shape}\")\n",
    "\n",
    "# Use first teacher as biased reference model\n",
    "biased_model = teachers[0]\n",
    "print(f\"Using teachers[0] as biased reference model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Define Experiment Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "from train import train_student\n",
    "from eval import print_results\n",
    "\n",
    "def run_experiment(exp_name, alpha, gamma, use_agre=True):\n",
    "    \"\"\"\n",
    "    Run a single experiment with resume support.\n",
    "    \n",
    "    Args:\n",
    "        exp_name: Name for saving (e.g., 'baseline', 'exp1_alpha07')\n",
    "        alpha: Weight for KD vs CE (1.0 = pure KD)\n",
    "        gamma: Weight for feature distillation (0.0 = no features)\n",
    "        use_agre: Use gradient-based teacher weighting\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXPERIMENT: {exp_name}\")\n",
    "    print(f\"  alpha={alpha}, gamma={gamma}, use_agre={use_agre}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Check if already completed\n",
    "    results_path = os.path.join(CHECKPOINT_DIR, f'student_{exp_name}_results.pt')\n",
    "    if os.path.exists(results_path):\n",
    "        print(f\"Experiment already completed! Loading results...\")\n",
    "        results = torch.load(results_path)\n",
    "        print_results(results['test_results'], f\"{exp_name} (cached)\")\n",
    "        return results['test_results']\n",
    "    \n",
    "    # Check for resume checkpoint\n",
    "    resume_path = os.path.join(CHECKPOINT_DIR, f'student_{exp_name}_latest.pt')\n",
    "    if os.path.exists(resume_path):\n",
    "        print(f\"Found checkpoint, will resume...\")\n",
    "    else:\n",
    "        resume_path = None\n",
    "    \n",
    "    # Create config\n",
    "    config = Config(\n",
    "        data_dir=DATA_DIR,\n",
    "        checkpoint_dir=CHECKPOINT_DIR,\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        epochs=30,\n",
    "        lr=0.001,\n",
    "        batch_size=32,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    student, history, test_results = train_student(\n",
    "        config=config,\n",
    "        teachers=teachers,\n",
    "        biased_model=biased_model,\n",
    "        exp_name=exp_name,\n",
    "        use_agre=use_agre,\n",
    "        checkpoint_path=resume_path,\n",
    "    )\n",
    "    \n",
    "    # Save to log\n",
    "    log_experiment(exp_name, alpha, gamma, test_results)\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "\n",
    "def log_experiment(exp_name, alpha, gamma, results):\n",
    "    \"\"\"Log experiment results to JSON file.\"\"\"\n",
    "    log_path = os.path.join(LOG_DIR, 'experiment_results.json')\n",
    "    \n",
    "    if os.path.exists(log_path):\n",
    "        with open(log_path, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        all_results = {}\n",
    "    \n",
    "    all_results[exp_name] = {\n",
    "        'alpha': alpha,\n",
    "        'gamma': gamma,\n",
    "        'wga': results['wga'],\n",
    "        'avg_acc': results['avg_acc'],\n",
    "        'group_accs': results['group_accs'],\n",
    "        'acc_gap': results['acc_gap'],\n",
    "    }\n",
    "    \n",
    "    with open(log_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {log_path}\")\n",
    "\n",
    "\n",
    "print(\"Experiment runner ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Run Experiments\n",
    "\n",
    "Run these cells one at a time. Each experiment takes ~2 hours.\n",
    "\n",
    "If Colab disconnects, re-run cells 1-5, then resume the interrupted experiment cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Baseline (alpha=1.0, gamma=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE: Pure AGRE-KD (no class labels, no features)\n",
    "baseline_results = run_experiment(\n",
    "    exp_name='baseline',\n",
    "    alpha=1.0,\n",
    "    gamma=0.0,\n",
    "    use_agre=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Exp1-a (alpha=0.5, gamma=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 1a: Add class labels (alpha=0.5)\n",
    "exp1a_results = run_experiment(\n",
    "    exp_name='exp1_alpha05',\n",
    "    alpha=0.5,\n",
    "    gamma=0.0,\n",
    "    use_agre=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Exp1-b (alpha=0.7, gamma=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 1b: Add class labels (alpha=0.7)\n",
    "exp1b_results = run_experiment(\n",
    "    exp_name='exp1_alpha07',\n",
    "    alpha=0.7,\n",
    "    gamma=0.0,\n",
    "    use_agre=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Exp1-c (alpha=0.9, gamma=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 1c: Add class labels (alpha=0.9)\n",
    "exp1c_results = run_experiment(\n",
    "    exp_name='exp1_alpha09',\n",
    "    alpha=0.9,\n",
    "    gamma=0.0,\n",
    "    use_agre=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Exp2-a (alpha=1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 2a: Feature distillation (gamma=0.1)\n",
    "exp2a_results = run_experiment(\n",
    "    exp_name='exp2_gamma01',\n",
    "    alpha=1.0,\n",
    "    gamma=0.1,\n",
    "    use_agre=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Exp2-b (alpha=1.0, gamma=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 2b: Feature distillation (gamma=0.25)\n",
    "exp2b_results = run_experiment(\n",
    "    exp_name='exp2_gamma025',\n",
    "    alpha=1.0,\n",
    "    gamma=0.25,\n",
    "    use_agre=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Exp3-a (alpha=0.7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 3a: Combined (alpha=0.7, gamma=0.1)\n",
    "exp3a_results = run_experiment(\n",
    "    exp_name='exp3_a07_g01',\n",
    "    alpha=0.7,\n",
    "    gamma=0.1,\n",
    "    use_agre=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Exp3-b (alpha=0.9, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 3b: Combined (alpha=0.9, gamma=0.1)\n",
    "exp3b_results = run_experiment(\n",
    "    exp_name='exp3_a09_g01',\n",
    "    alpha=0.9,\n",
    "    gamma=0.1,\n",
    "    use_agre=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14: Compile Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all results\n",
    "log_path = os.path.join(LOG_DIR, 'experiment_results.json')\n",
    "with open(log_path, 'r') as f:\n",
    "    all_results = json.load(f)\n",
    "\n",
    "# Create summary table\n",
    "rows = []\n",
    "for exp_name, data in all_results.items():\n",
    "    rows.append({\n",
    "        'Experiment': exp_name,\n",
    "        'Alpha': data['alpha'],\n",
    "        'Gamma': data['gamma'],\n",
    "        'WGA (%)': f\"{data['wga']*100:.2f}\",\n",
    "        'Avg Acc (%)': f\"{data['avg_acc']*100:.2f}\",\n",
    "        'Gap (%)': f\"{data['acc_gap']*100:.2f}\",\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find best\n",
    "best_exp = max(all_results.items(), key=lambda x: x[1]['wga'])\n",
    "print(f\"\\nBest WGA: {best_exp[0]} with {best_exp[1]['wga']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 15: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load results\n",
    "log_path = os.path.join(LOG_DIR, 'experiment_results.json')\n",
    "with open(log_path, 'r') as f:\n",
    "    all_results = json.load(f)\n",
    "\n",
    "# Plot 1: WGA comparison bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "names = list(all_results.keys())\n",
    "wgas = [all_results[n]['wga'] * 100 for n in names]\n",
    "\n",
    "colors = ['#2ecc71' if w == max(wgas) else '#3498db' for w in wgas]\n",
    "axes[0].bar(names, wgas, color=colors)\n",
    "axes[0].set_ylabel('Worst-Group Accuracy (%)')\n",
    "axes[0].set_title('WGA by Experiment')\n",
    "axes[0].set_xticklabels(names, rotation=45, ha='right')\n",
    "axes[0].axhline(y=85, color='r', linestyle='--', label='AGRE-KD baseline (85%)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Per-group accuracy for best experiment\n",
    "best_name = max(all_results.keys(), key=lambda k: all_results[k]['wga'])\n",
    "best = all_results[best_name]\n",
    "group_names = ['Landbird+Land', 'Landbird+Water', 'Waterbird+Land', 'Waterbird+Water']\n",
    "group_accs = [best['group_accs'][str(i)] * 100 for i in range(4)]\n",
    "\n",
    "colors = ['#e74c3c' if g == min(group_accs) else '#3498db' for g in group_accs]\n",
    "axes[1].bar(group_names, group_accs, color=colors)\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title(f'Per-Group Accuracy: {best_name}')\n",
    "axes[1].set_xticklabels(group_names, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(LOG_DIR, 'results_visualization.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFigure saved to {LOG_DIR}/results_visualization.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
